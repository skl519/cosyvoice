



2）讲讲向量数据库，它和知识图谱的区别是什么?(库中各个实例之间的相关性)
text -> embedding 但是embeding中之间的关系被忽视
向量数据库专门用于存储和管理高维向量数据。这些向量通常是通过机器学习模型（如深度学习模型）从文本、图像或其他数据中生成的嵌入表示。
知识图谱是一种以图的形式表示知识的结构，其中节点代表实体（如人、地点、事物），边代表实体之间的关系（如“属于”、“位于”等）

3）你觉得GraphRAG构建知识图谱的方式有何特点?(讲讲GraphRAG的定义、对子图的划分和排序等等)
indexing:
    文档分块，提取实体和关系，构建知识图谱
    划分社区: 递归地检测每个检测到的社区内的子社区，直到达到无法再分区的叶子社区
    生成社区摘要:摘要是按照提取的社区的层次结构自底向上地生成的，其中层次结构的高层摘要递归地结合了低层摘要
querying:
    global: 社区摘要被随机洗牌并划分为预先指定的标记大小的块,使用LLM对每个块进行评分，保留高分作为输入
    local: 提取查询中的实体，并在知识图谱中进行检索，提取文本映射和关系，以及社区摘要，这些作为输入

4）大家对GarphRAG的期望比较高，但在实际业务中并没有带来比较好的效果，你觉得这个原因是什么?
图结构构建成本高, 推理计算资源消耗大
领域适配性差：大多数研究集中在通用领域，而业务场景往往需要垂直领域的图谱，迁移效果不佳
图谱质量问题： 图谱构建过程中实体链接、关系抽取的错误会直接影响下游RAG的效果，甚至可能误导模型生成错误或不相关的答案
全面性多样性问题


2）是怎么做数据做标注的?人工or自动?如果是人工，如何判断数据质量好坏? 数据标注的策略具体是什么？(解释标注方案)
rag微调：
    收集bad case: 先使用多个rag开源框架进行生成，然后人工判断是否需要修正，如果不佳，使用人工标注，之后在对多个生成结果进行重排序

1）数据清洗的过程中，用到了多少个算子，具体是哪些算子?
文本清洗算子 (Text Cleaning Operator):例如去除标点符号、特殊字符、空格，停用词，文本切分等。

1）如何解决 LLMS 测试集数据泄露问题:
    构建一个独立私有的数据集
    语义去重: 使用嵌入模型检测测试样本与训练数据（或其子集）之间是否存在语义上的高度相似性，并移除这些样本。
    抽样检查: 如果无法访问完整的训练数据，可以对模型的训练数据来源（如Common Crawl的特定快照）进行抽样，检查测试样本是否在其中出现。
    严格去重: 在构建测试集时，以及（如果可能）在处理训练数据时，使用严格的去重技术（如精确匹配、n-gram重叠、编辑距离、基于哈希的指纹如MinHash）
                来移除与训练数据高度相似或完全相同的样本。

2）是否接触过 embeding 模型的微调方法?
    对比学习微调 (Contrastive Learning Fine-tuning)
        方法: 其核心思想是拉近相似样本（正样本对）的向量距离，推开不相似样本（负样本对）的向量距离。
                需要构建正负样本对或三元组（Anchor, Positive, Negative）
    监督式微调：
        数据构建:成对数据: (查询, 文档片段) 对。
        标签:
            相关性得分 (Regression): 为每个(查询, 文档片段)对标注一个连续的相关性分数（如0到1之间，或1到5分）。
                                        模型学习预测这个分数。损失函数常用 均方误差 (MSE Loss) 或 余弦相似度损失 (Cosine Similarity Loss)。
            相关性类别 (Classification): 将相关性划分为几个离散类别（如“高度相关”、“部分相关”、“不相关”）。
                                        模型学习预测这个类别。损失函数常用 交叉熵损失 (Cross-Entropy Loss)。


3）哪些省内存的大语言模型训练/微调/推理方法?
    mha2mla
    量化剪枝
    混精度训练，梯度累计
    分布式训练

4）模型训练的数据集问题:一般数据集哪里找?
    特定领域：论文使用的数据集
    Hugging Face Datasets
    Kaggle Datasets
    Google Dataset Search
    Papers With Code

5）搭建大模型应用遇到过那些问题?如何解决的?
    端到端评估困难 (End-to-End Evaluation Difficulty):
    评估RAG系统效果复杂。不仅要看检索的准确率/召回率，还要看最终生成答案的准确性、相关性、流畅性、忠实性。
    缺乏标准化的、自动化的端到端评估指标和数据集，很多时候依赖人工评估。
                                                                                                                                                                                    
6）是否了解上下文压缩方法?
    减少输入给大语言模型（LLM）的上下文长度，以适应模型的上下文窗口限制，并提高处理效率、降低成本。
    筛选与选择：段句分块，去除无关的文本内容（嵌入向量和余弦相似度）；只保留包含特定关键词、命名实体或满足特定规则的文本部分
    检索过滤：通过大模型对无关信息进行剔除和总结，分为直接抽取重要句子，或者生成摘要
    信息抽取：将文本中的实体和关系抽取出来，只将这些关键事实输入模型，而不是完整的段落
    
9）LLMS受到上下文长度的限制，如果检索到的文档带有太多噪声，该如何解决这样的问题?
    筛选与选择：段句分块，去除无关的文本内容（嵌入向量和余弦相似度）；只保留包含特定关键词、命名实体或满足特定规则的文本部分
    检索过滤：通过大模型对无关信息进行剔除和总结，分为直接抽取重要句子，或者生成摘要
    信息抽取：将文本中的实体和关系抽取出来，只将这些关键事实输入模型，而不是完整的段落

10）RAG(检索增强生成)对于大模型来说，有什么好处?
11）业内常用的分布式AI框架有哪些?
    pytorch
    deepspeed
    Colossal-AI


indexing:
    文本分块：文本清洗1024词的内的段落
    构建fiass和es数据库：将文本和图片使用clip进行编码
    使用开源的hipporag框架建立知识图谱

querying:
    使用蒸馏版的qwen2小模型来判断是否是总结性问题
    对于具体的问题：
        先使用es数据库进行bm25预检索，对检索到的数据在进行语义检索，得到检索到的图片和文本，
                对于文本：对topk内直接作为输入，topk外的文本使用llm和query做一个总结作为输入
                对于图片：相似度大于某阈值（0.6）的图片作为输入
    对于总结性问题：
        使用graphrag框架进行知识图谱的全局检索

同时收集badcase和固定输入输出的1000左右样本，使用llmamfactory进行微调，2 h,2 epoch
对文档中的300个图片和文本的对应作为数据集，对clip模型进行微调
语音识别和语音合成的模块